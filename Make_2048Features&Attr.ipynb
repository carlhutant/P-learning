{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn import preprocessing\n",
    "import matplotlib.pyplot as plt\n",
    "from scipy.stats import norm\n",
    "import os, sys\n",
    "\n",
    "import keras\n",
    "from keras.layers import Input, Dense, Lambda, Reshape, Flatten, Dropout\n",
    "from keras.layers import Reshape, Conv2D, Conv2DTranspose, LeakyReLU\n",
    "from keras.layers.normalization import BatchNormalization\n",
    "from keras.models import Model, load_model\n",
    "from keras.utils.data_utils import Sequence\n",
    "from keras import backend as K\n",
    "from keras.utils import to_categorical\n",
    "from keras.applications.resnet import ResNet101,preprocess_input\n",
    "from keras.callbacks import ReduceLROnPlateau\n",
    "from keras.callbacks import EarlyStopping\n",
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "from keras.models import load_model\n",
    "from sklearn.utils import class_weight\n",
    "import tensorflow as tf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "###########change dataset here##########\n",
    "dataset = 'plant'\n",
    "########################################\n",
    "\n",
    "batch_size = 128\n",
    "image_size = 224\n",
    "train_dir = './data/{}/IMG/train'.format(dataset)\n",
    "val_dir = './data/{}/IMG/val'.format(dataset)\n",
    "test_dir = './data/{}/IMG/test'.format(dataset)\n",
    "attr_binary_path = './data/{}/predicate-matrix-binary.txt'.format(dataset)\n",
    "attr_continous_path = './data/{}/predicate-matrix-continuous.txt'.format(dataset)\n",
    "\n",
    "\n",
    "classname = pd.read_csv('./data/{}/classes.txt'.format(dataset), header=None, sep='\\t')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /home/uscc/.pyenv/versions/3.6.8/lib/python3.6/site-packages/keras/backend/tensorflow_backend.py:541: The name tf.placeholder is deprecated. Please use tf.compat.v1.placeholder instead.\n",
      "\n",
      "WARNING:tensorflow:From /home/uscc/.pyenv/versions/3.6.8/lib/python3.6/site-packages/keras/backend/tensorflow_backend.py:4432: The name tf.random_uniform is deprecated. Please use tf.random.uniform instead.\n",
      "\n",
      "WARNING:tensorflow:From /home/uscc/.pyenv/versions/3.6.8/lib/python3.6/site-packages/keras/backend/tensorflow_backend.py:66: The name tf.get_default_graph is deprecated. Please use tf.compat.v1.get_default_graph instead.\n",
      "\n",
      "WARNING:tensorflow:From /home/uscc/.pyenv/versions/3.6.8/lib/python3.6/site-packages/keras/backend/tensorflow_backend.py:190: The name tf.get_default_session is deprecated. Please use tf.compat.v1.get_default_session instead.\n",
      "\n",
      "WARNING:tensorflow:From /home/uscc/.pyenv/versions/3.6.8/lib/python3.6/site-packages/keras/backend/tensorflow_backend.py:197: The name tf.ConfigProto is deprecated. Please use tf.compat.v1.ConfigProto instead.\n",
      "\n",
      "WARNING:tensorflow:From /home/uscc/.pyenv/versions/3.6.8/lib/python3.6/site-packages/keras/backend/tensorflow_backend.py:2041: The name tf.nn.fused_batch_norm is deprecated. Please use tf.compat.v1.nn.fused_batch_norm instead.\n",
      "\n",
      "WARNING:tensorflow:From /home/uscc/.pyenv/versions/3.6.8/lib/python3.6/site-packages/keras/backend/tensorflow_backend.py:4267: The name tf.nn.max_pool is deprecated. Please use tf.nn.max_pool2d instead.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "model_ft = load_model('./model/{}/FineTuneResNet101.h5'.format(dataset))\n",
    "# model_rt = load_model('./model/{}/RetrainResNet101.h5'.format(dataset))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 36936 images belonging to 25 classes.\n",
      "Found 9230 images belonging to 25 classes.\n",
      "Found 24129 images belonging to 13 classes.\n"
     ]
    }
   ],
   "source": [
    "image_gen = ImageDataGenerator(preprocessing_function=preprocess_input)\n",
    "train_gen = image_gen.flow_from_directory(\n",
    "    batch_size=batch_size,\n",
    "    directory=train_dir,\n",
    "    color_mode=\"rgb\",\n",
    "    target_size=(image_size,image_size),\n",
    "    class_mode='sparse',\n",
    "    seed = 42\n",
    ")\n",
    "\n",
    "\n",
    "val_gen = image_gen.flow_from_directory(\n",
    "    batch_size=batch_size,\n",
    "    directory=val_dir,\n",
    "    target_size=(image_size, image_size),\n",
    "    class_mode='sparse',\n",
    "    color_mode=\"rgb\",\n",
    "    seed = 42\n",
    "    \n",
    ")\n",
    "\n",
    "test_gen = image_gen.flow_from_directory(\n",
    "    batch_size = batch_size,\n",
    "    directory = test_dir,\n",
    "    target_size=(image_size, image_size),\n",
    "    class_mode='sparse',\n",
    "    color_mode=\"rgb\",\n",
    "    seed = 42\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 0,  0,  0, ..., 24, 24, 24], dtype=int32)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_gen.classes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Binary attr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "attr_list_b = []\n",
    "RealCE_binary = pd.read_csv(attr_binary_path,header=None,sep='\\t')\n",
    "for idx in range(len(RealCE_binary)):\n",
    "    tmp = RealCE_binary[0][idx].split(' ')\n",
    "    attr = [float(i) for i in tmp if i!='']\n",
    "    attr = np.array(attr)\n",
    "    attr_list_b.append(attr)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Continous"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "attr_list_c = []\n",
    "RealCE_continous = pd.read_csv(attr_continous_path,header=None,sep = '\\t')\n",
    "for idx in range(len(RealCE_continous)):\n",
    "    tmp = RealCE_continous[0][idx].split(' ')\n",
    "    attr = [float(i) for i in tmp if i!='']\n",
    "    attr = np.array(attr)\n",
    "    attr_list_c.append(attr)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Continous attr min max"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "attr_list_cmm = []\n",
    "RealCE_continous = pd.read_csv(attr_continous_path,header=None,sep = '\\t')\n",
    "for idx in range(len(RealCE_continous)):\n",
    "    tmp = RealCE_continous[0][idx].split(' ')\n",
    "    attr = [float(i) for i in tmp if i!='']\n",
    "    attr = np.array(attr)\n",
    "    attr = (attr - np.min(attr)) / (np.max(attr) - np.min(attr))\n",
    "    attr_list_cmm.append(attr)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Continous attr mean std"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "attr_list_cms = []\n",
    "RealCE_continous = pd.read_csv(attr_continous_path,header=None,sep = '\\t')\n",
    "for idx in range(len(RealCE_continous)):\n",
    "    tmp = RealCE_continous[0][idx].split(' ')\n",
    "    attr = [float(i) for i in tmp if i!='']\n",
    "    attr = np.array(attr)\n",
    "    attr = (attr - np.mean(attr)) / np.std(attr)\n",
    "    attr_list_cms.append(attr)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### make the convert_attr_list for train,val"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_attr_list_b = []\n",
    "train_attr_list_c = []\n",
    "train_attr_list_cmm = []\n",
    "train_attr_list_cms = []\n",
    "\n",
    "for k ,v in train_gen.class_indices.items():\n",
    "    idx = np.where(classname[1] == k)\n",
    "    train_attr_list_b.append(attr_list_b[idx[0][0]])\n",
    "    train_attr_list_c.append(attr_list_c[idx[0][0]])\n",
    "    train_attr_list_cmm.append(attr_list_cmm[idx[0][0]])\n",
    "    train_attr_list_cms.append(attr_list_cms[idx[0][0]])\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### make the convert_attr_list for test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_attr_list_b = []\n",
    "test_attr_list_c = []\n",
    "test_attr_list_cmm = []\n",
    "test_attr_list_cms = []\n",
    "\n",
    "for k ,v in test_gen.class_indices.items():\n",
    "    idx = np.where(classname[1] == k)\n",
    "    test_attr_list_b.append(attr_list_b[idx[0][0]])\n",
    "    test_attr_list_c.append(attr_list_c[idx[0][0]])\n",
    "    test_attr_list_cmm.append(attr_list_cmm[idx[0][0]])\n",
    "    test_attr_list_cms.append(attr_list_cms[idx[0][0]])\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## train data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(36936, 2048)\n",
      "(0, 2048)\n",
      "(36936, 35)\n",
      "(36936, 46)\n",
      "(36936, 46)\n",
      "(36936, 46)\n",
      "(36936,)\n"
     ]
    }
   ],
   "source": [
    "count = 0\n",
    "ft_feature = np.array([],dtype='float32').reshape(0,2048)\n",
    "rt_feature = np.array([],dtype='float32').reshape(0,2048)\n",
    "\n",
    "attr_b = []\n",
    "attr_c = []\n",
    "attr_cmm = []\n",
    "attr_cms = []\n",
    "label_list = []\n",
    "while count < train_gen.n:\n",
    "    data,label = train_gen.next()\n",
    "    # fine tune feature\n",
    "    after_predict = model_ft.predict(data)\n",
    "    ft_feature = np.concatenate((ft_feature,after_predict))\n",
    "    \n",
    "    # retrain feature\n",
    "#     after_predict = model_rt.predict(data)\n",
    "#     rt_feature = np.concatenate((rt_feature,after_predict))\n",
    "    \n",
    "    # attr\n",
    "    for l in label:\n",
    "        attr_b.append(train_attr_list_b[int(l)])\n",
    "        attr_c.append(train_attr_list_c[int(l)])\n",
    "        attr_cmm.append(train_attr_list_cmm[int(l)])\n",
    "        attr_cms.append(train_attr_list_cms[int(l)])\n",
    "    \n",
    "        # label \n",
    "        label_list.append(int(l))\n",
    "    \n",
    "    count += len(data)\n",
    "\n",
    "attr_b = np.array(attr_b)\n",
    "attr_c = np.array(attr_c)\n",
    "attr_cmm = np.array(attr_cmm)\n",
    "attr_cms = np.array(attr_cms)\n",
    "label_list = np.array(label_list)\n",
    "\n",
    "print(ft_feature.shape)\n",
    "print(rt_feature.shape)\n",
    "print(attr_b.shape)\n",
    "print(attr_c.shape)\n",
    "print(attr_cmm.shape)\n",
    "print(attr_cms.shape)\n",
    "print(label_list.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.save('./data/{}/feature_label_attr/train/train_feature_ft.npy'.format(dataset),ft_feature)\n",
    "np.save('./data/{}/feature_label_attr/train/train_feature_rt.npy'.format(dataset),rt_feature)\n",
    "\n",
    "np.save('./data/{}/feature_label_attr/train/train_attr_b.npy'.format(dataset),attr_b)\n",
    "np.save('./data/{}/feature_label_attr/train/train_attr_c.npy'.format(dataset),attr_c)\n",
    "np.save('./data/{}/feature_label_attr/train/train_attr_cmm.npy'.format(dataset),attr_cmm)\n",
    "np.save('./data/{}/feature_label_attr/train/train_attr_cms.npy'.format(dataset),attr_cms)\n",
    "\n",
    "np.save('./data/{}/feature_label_attr/train/train_label.npy'.format(dataset),label_list)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## val data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(9230, 2048)\n",
      "(0, 2048)\n",
      "(9230, 35)\n",
      "(9230, 46)\n",
      "(9230, 46)\n",
      "(9230, 46)\n",
      "(9230,)\n"
     ]
    }
   ],
   "source": [
    "count = 0\n",
    "ft_feature = np.array([],dtype='float32').reshape(0,2048)\n",
    "rt_feature = np.array([],dtype='float32').reshape(0,2048)\n",
    "\n",
    "attr_b = []\n",
    "attr_c = []\n",
    "attr_cmm = []\n",
    "attr_cms = []\n",
    "label_list = []\n",
    "while count < val_gen.n:\n",
    "    data,label = val_gen.next()\n",
    "    # fine tune feature\n",
    "    after_predict = model_ft.predict(data)\n",
    "    ft_feature = np.concatenate((ft_feature,after_predict))\n",
    "    \n",
    "    # retrain feature\n",
    "#     after_predict = model_rt.predict(data)\n",
    "#     rt_feature = np.concatenate((rt_feature,after_predict))\n",
    "    \n",
    "    # attr\n",
    "    for l in label:\n",
    "        attr_b.append(train_attr_list_b[int(l)])\n",
    "        attr_c.append(train_attr_list_c[int(l)])\n",
    "        attr_cmm.append(train_attr_list_cmm[int(l)])\n",
    "        attr_cms.append(train_attr_list_cms[int(l)])\n",
    "    \n",
    "        # label \n",
    "        label_list.append(int(l))\n",
    "    \n",
    "    count += len(data)\n",
    "\n",
    "attr_b = np.array(attr_b)\n",
    "attr_c = np.array(attr_c)\n",
    "attr_cmm = np.array(attr_cmm)\n",
    "attr_cms = np.array(attr_cms)\n",
    "label_list = np.array(label_list)\n",
    "\n",
    "print(ft_feature.shape)\n",
    "print(rt_feature.shape)\n",
    "print(attr_b.shape)\n",
    "print(attr_c.shape)\n",
    "print(attr_cmm.shape)\n",
    "print(attr_cms.shape)\n",
    "print(label_list.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.save('./data/{}/feature_label_attr/val/val_feature_ft.npy'.format(dataset),ft_feature)\n",
    "np.save('./data/{}/feature_label_attr/val/val_feature_rt.npy'.format(dataset),rt_feature)\n",
    "\n",
    "np.save('./data/{}/feature_label_attr/val/val_attr_b.npy'.format(dataset),attr_b)\n",
    "np.save('./data/{}/feature_label_attr/val/val_attr_c.npy'.format(dataset),attr_c)\n",
    "np.save('./data/{}/feature_label_attr/val/val_attr_cmm.npy'.format(dataset),attr_cmm)\n",
    "np.save('./data/{}/feature_label_attr/val/val_attr_cms.npy'.format(dataset),attr_cms)\n",
    "\n",
    "np.save('./data/{}/feature_label_attr/val/val_label.npy'.format(dataset),label_list)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## test data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(24129, 2048)\n",
      "(0, 2048)\n",
      "(24129, 35)\n",
      "(24129, 46)\n",
      "(24129, 46)\n",
      "(24129, 46)\n",
      "(24129,)\n"
     ]
    }
   ],
   "source": [
    "count = 0\n",
    "ft_feature = np.array([],dtype='float32').reshape(0,2048)\n",
    "rt_feature = np.array([],dtype='float32').reshape(0,2048)\n",
    "\n",
    "attr_b = []\n",
    "attr_c = []\n",
    "attr_cmm = []\n",
    "attr_cms = []\n",
    "label_list = []\n",
    "while count < test_gen.n:\n",
    "    data,label = test_gen.next()\n",
    "    # fine tune feature\n",
    "    after_predict = model_ft.predict(data)\n",
    "    ft_feature = np.concatenate((ft_feature,after_predict))\n",
    "    \n",
    "    # retrain feature\n",
    "#     after_predict = model_rt.predict(data)\n",
    "#     rt_feature = np.concatenate((rt_feature,after_predict))\n",
    "    \n",
    "    # attr\n",
    "    for l in label:\n",
    "        attr_b.append(test_attr_list_b[int(l)])\n",
    "        attr_c.append(test_attr_list_c[int(l)])\n",
    "        attr_cmm.append(test_attr_list_cmm[int(l)])\n",
    "        attr_cms.append(test_attr_list_cms[int(l)])\n",
    "    \n",
    "        # label \n",
    "        label_list.append(int(l))\n",
    "    \n",
    "    count += len(data)\n",
    "\n",
    "attr_b = np.array(attr_b)\n",
    "attr_c = np.array(attr_c)\n",
    "attr_cmm = np.array(attr_cmm)\n",
    "attr_cms = np.array(attr_cms)\n",
    "label_list = np.array(label_list)\n",
    "\n",
    "print(ft_feature.shape)\n",
    "print(rt_feature.shape)\n",
    "print(attr_b.shape)\n",
    "print(attr_c.shape)\n",
    "print(attr_cmm.shape)\n",
    "print(attr_cms.shape)\n",
    "print(label_list.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.save('./data/{}/feature_label_attr/test/test_feature_ft.npy'.format(dataset),ft_feature)\n",
    "np.save('./data/{}/feature_label_attr/test/test_feature_rt.npy'.format(dataset),rt_feature)\n",
    "\n",
    "np.save('./data/{}/feature_label_attr/test/test_attr_b.npy'.format(dataset),attr_b)\n",
    "np.save('./data/{}/feature_label_attr/test/test_attr_c.npy'.format(dataset),attr_c)\n",
    "np.save('./data/{}/feature_label_attr/test/test_attr_cmm.npy'.format(dataset),attr_cmm)\n",
    "np.save('./data/{}/feature_label_attr/test/test_attr_cms.npy'.format(dataset),attr_cms)\n",
    "\n",
    "np.save('./data/{}/feature_label_attr/test/test_label.npy'.format(dataset),label_list)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
